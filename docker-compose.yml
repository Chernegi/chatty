version: '3.4'

services:
  ollama-llm:
    image: chernegi/ollama-mistral:v0.1.0
    environment:
      - GIN_MODE=release
    container_name: ollama-llm
    hostname: ollamahost
    ports:
      - 11434:11434
    networks:
      - chatty-net
    restart: unless-stopped

  chatty:
    # build: ./
    image: chernegi/chatty:v0.1.0
    environment:
      - OLLAMA_URL=http://ollamahost:11434
    depends_on: 
      - ollama-llm
    container_name: chatty-app
    command: echo "starting streamlit"
    tty: true
    hostname: chattyhost
    ports:
      - 8501:8501
    networks:
      - chatty-net
    restart: always

networks:
  chatty-net: