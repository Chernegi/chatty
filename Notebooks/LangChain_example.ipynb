{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Cheat Sheet\n",
    "\n",
    "GitHub: https://github.com/hwchase17/langchain\n",
    "\n",
    "Docs: https://python.langchain.com/en/latest/index.html\n",
    "\n",
    "End-2-end example: https://github.com/langchain-ai/chat-langchain\n",
    "\n",
    "LLM LocalRun: https://python.langchain.com/docs/guides/local_llms\n",
    "\n",
    "\n",
    "\n",
    "**Content**\n",
    "- **llms**\n",
    "- **PromptTemplates**\n",
    "- **Chains**\n",
    "- **Agents and Tools**\n",
    "- **Memory**\n",
    "- **Document Loaders**\n",
    "- **Indexes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open(\"..//config.yml\"))\n",
    "os.environ[\"OPENAI_API_KEY\"] = config['openai_key']\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = config['huggingface_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs\n",
    "### Generic Interface for LLMs\n",
    "\n",
    "**LLM provibers:** https://python.langchain.com/docs/modules/model_io/llms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nToday I arrived in Kyiv. '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"translate Ukrainian to English: Сьогодні я приїхав до Києва\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/google/flan-t5-xl\n",
    "# llm = HuggingFaceHub(repo_id=\"bert-base-uncased\")\n",
    "# llm(\"translate English to German: Today I arrived in Kiev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"Question: {question} Let's think step by step. Answer: \"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_str = prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No, it is not possible for Barack Obama to have a conversation with George Washington, as Washington passed away in 1799, long before Obama was born in 1961. They lived in different time periods and were never alive at the same time. '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(formated_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technically, no. Barack Obama and George Washington lived in different centuries and did not overlap in time. However, if we were to imagine a hypothetical scenario where they could have a conversation, it would be possible to do so through the use of technology and advanced historical research. Here is a potential step-by-step process:\n",
      "\n",
      "1. Historical research: In order for this conversation to take place, thorough research would need to be conducted on both Barack Obama and George Washington. This would involve studying their backgrounds, beliefs, and major events in their lives.\n",
      "\n",
      "2. Creation of a simulation: With the help of advanced technology, a simulation of both individuals could be created. This simulation would be based on historical data and would accurately depict their appearance, voice, and mannerisms.\n",
      "\n",
      "3. Programming of conversation: Next, the conversation between the two individuals would need to be programmed. This would involve the use of artificial intelligence and natural language processing to ensure that the conversation is realistic and accurate.\n",
      "\n",
      "4. Testing and refining: The simulation and conversation would need to be thoroughly tested and refined to ensure that it accurately reflects both individuals and their views.\n",
      "\n",
      "5. Virtual meeting: Finally, a virtual meeting could take place where Barack Obama and George Washington, in their simulated forms, could engage in a conversation.\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"Can Barack Obama have a conversation with George Washington?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! poetry add wikipedia\n",
    "# ! poetry add numexpr\n",
    "# ! pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the year the film was released and then use the calculator to calculate the power.\n",
      "Action: Wikipedia\n",
      "Action Input: Departed with Leonardo Dicaprio\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Leonardo DiCaprio filmography\n",
      "Summary: Leonardo DiCaprio is an American actor who began his career performing as a child on television. He appeared on the shows The New Lassie (1989) and Santa Barbara (1990) and also had long running roles in the comedy-drama Parenthood (1990) and the sitcom Growing Pains (1991). DiCaprio played Tobias \"Toby\" Wolff opposite Robert De Niro in the biographical coming-of-age drama This Boy's Life in 1993. In the same year, he had a supporting role as a developmentally disabled boy Arnie Grape in What's Eating Gilbert Grape, which earned him nominations for the Academy Award for Best Supporting Actor and the Golden Globe Award for Best Supporting Actor – Motion Picture. In 1995, DiCaprio played the leading roles of an American author Jim Carroll in The Basketball Diaries and the French poet Arthur Rimbaud in Total Eclipse. The following year he played Romeo Montague in the Baz Luhrmann-directed film Romeo + Juliet (1996). DiCaprio starred with Kate Winslet in the James Cameron-directed film Titanic (1997). The film became the highest grossing at the worldwide box-office, and made him famous globally. For his performance as Jack Dawson, he received the MTV Movie Award for Best Male Performance and his first nomination for the Golden Globe Award for Best Actor – Motion Picture Drama.In 2002, DiCaprio played con-artist Frank Abagnale, Jr. opposite Tom Hanks in the Steven Spielberg-directed biographical crime-drama Catch Me If You Can and also starred in the Martin Scorsese-directed historical drama Gangs of New York. He founded his own production company, Appian Way, in 2004. The next two films he starred in were both directed by Scorsese: the Howard Hughes biopic The Aviator (2004) and the crime drama The Departed (2006). For his portrayal of Hughes in the former, DiCaprio won the Golden Globe Award for Best Actor – Motion Picture Drama and garnered his first nomination for the Academy Award for Best Actor.DiCaprio produced the environmental documentary The 11th Hour and the comedy drama Gardener of Eden in 2007. The following year, he reunited with Kate Winslet in the Sam Mendes-directed drama Revolutionary Road and appeared in the Ridley Scott-directed action film Body of Lies. DiCaprio reteamed with Scorsese in 2010 in the psychological thriller Shutter Island and also starred in the Christopher Nolan-directed science fiction heist thriller Inception. In 2011, he portrayed J. Edgar Hoover, the first director of the FBI, in the biopic J. Edgar. The following year, he played a supporting role in the Quentin Tarantino-directed western Django Unchained. DiCaprio starred in two film adaptations of novels in 2013; he first appeared as Jay Gatsby in the Luhrmann-directed adaptation of F. Scott Fitzgerald's novel The Great Gatsby, and later as Jordan Belfort in The Wolf of Wall Street, an adaptation of Belfort's memoir of the same name. The latter earned him a third Academy Award nomination for Best Actor and a Golden Globe Award for Best Actor – Motion Picture Musical or Comedy. In 2015, DiCaprio played fur trapper Hugh Glass in the survival drama The Revenant, for which he won the Academy Award for Best Actor. In 2019, he starred as an actor on the decline in the Tarantino-directed comedy-drama Once Upon a Time in Hollywood with Brad Pitt and Margot Robbie.\n",
      "\n",
      "\n",
      "\n",
      "Page: Leonardo DiCaprio\n",
      "Summary: Leonardo Wilhelm DiCaprio (; Italian: [diˈkaːprjo]; born November 11, 1974) is an American actor and film producer. Known for his work in biographical and period films, he is the recipient of numerous accolades, including an Academy Award, a British Academy Film Award, and three Golden Globe Awards. As of 2019, his films have grossed over $7.2 billion worldwide, and he has been placed eight times in annual rankings of the world's highest-paid actors.\n",
      "Born in Los Angeles, DiCaprio began his career in the late 1980s by appearing in television commercials. In the early 1990s, he had recurring roles in various t\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the film was released in 2006.\n",
      "Action: Calculator\n",
      "Action Input: 2006^0.43\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The film Departed with Leonardo Dicaprio was released in 2006 and this year raised to the 0.43 power is 26.30281917656938.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The film Departed with Leonardo Dicaprio was released in 2006 and this year raised to the 0.43 power is 26.30281917656938.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about AI?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Absolutely! What would you like to know about AI?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can we talk about AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about AI?\n",
      "AI:  Absolutely! What would you like to know about AI?\n",
      "Human: I'm interested in Reinforcement Learning.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure! Reinforcement Learning is a type of machine learning algorithm that allows an AI agent to learn from its environment by taking actions and receiving rewards or punishments. It is used to solve complex problems that require trial and error. Would you like to know more about how it works?'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I'm interested in Reinforcement Learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documant Loaders\n",
    "\n",
    "Doc: https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "\n",
    "loader = NotionDirectoryLoader(\"Notion_DB\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! poerty add sentence_transformers\n",
    "# ! poetry add faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "  f.write(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Splitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 944kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 292kB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 4.16MB/s]\n",
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 1.30MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 286kB/s]\n",
      "data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 374kB/s]\n",
      "pytorch_model.bin:  89%|████████▊ | 388M/438M [00:52<00:05, 8.71MB/s] "
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "#text = \"This is a test document.\"\n",
    "#query_result = embeddings.embed_query(text)\n",
    "#doc_result = embeddings.embed_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"faiss_index\")\n",
    "new_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "docs = new_db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatty-gFk8BLC2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
